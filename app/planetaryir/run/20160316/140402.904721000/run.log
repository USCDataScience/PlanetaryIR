2016-03-16 14:04:06.039044 # on Snehas-MacBook-Pro.local: deepdive do person_mention
2016-03-16 14:04:06.039397 # run/20160316/140402.904721000/plan.sh
2016-03-16 14:04:06.039431 # execution plan for data/person_mention
2016-03-16 14:04:06.039455 
2016-03-16 14:04:06.039480 : ## process/init/app ##########################################################
2016-03-16 14:04:06.039504 : # Done: 2016-02-24T19:00:00-0600 (20d 18h 4m 3s ago)
2016-03-16 14:04:06.039522 : process/init/app/run.sh
2016-03-16 14:04:06.039547 : mark_done process/init/app
2016-03-16 14:04:06.039564 : ##############################################################################
2016-03-16 14:04:06.039581 
2016-03-16 14:04:06.039697 : ## process/init/relation/articles ############################################
2016-03-16 14:04:06.039744 : # Done: 2016-03-16T12:21:16-0500 (1h 42m 47s ago)
2016-03-16 14:04:06.039776 : process/init/relation/articles/run.sh
2016-03-16 14:04:06.039802 : mark_done process/init/relation/articles
2016-03-16 14:04:06.039830 : ##############################################################################
2016-03-16 14:04:06.039857 
2016-03-16 14:04:06.039882 : ## data/articles #############################################################
2016-03-16 14:04:06.039907 : # Done: 2016-03-16T12:21:16-0500 (1h 42m 47s ago)
2016-03-16 14:04:06.039932 : # no-op
2016-03-16 14:04:06.039960 : mark_done data/articles
2016-03-16 14:04:06.039988 : ##############################################################################
2016-03-16 14:04:06.040016 
2016-03-16 14:04:06.040037 : ## process/ext_sentences_by_nlp_markup #######################################
2016-03-16 14:04:06.040062 : # Done: 2016-03-16T12:23:51-0500 (1h 40m 12s ago)
2016-03-16 14:04:06.040086 : process/ext_sentences_by_nlp_markup/run.sh
2016-03-16 14:04:06.040112 : mark_done process/ext_sentences_by_nlp_markup
2016-03-16 14:04:06.040135 : ##############################################################################
2016-03-16 14:04:06.040158 
2016-03-16 14:04:06.040184 : ## data/sentences ############################################################
2016-03-16 14:04:06.040219 : # Done: 2016-03-16T12:23:51-0500 (1h 40m 12s ago)
2016-03-16 14:04:06.040246 : # no-op
2016-03-16 14:04:06.040273 : mark_done data/sentences
2016-03-16 14:04:06.040299 : ##############################################################################
2016-03-16 14:04:06.040326 
2016-03-16 14:04:06.040347 ## process/ext_person_mention_by_map_person_mention ##########################
2016-03-16 14:04:06.040366 : # Done: 2016-03-16T13:57:18-0500 (6m 45s ago)
2016-03-16 14:04:06.040394 # Done: 2016-03-16T13:57:18-0500 (6m 44s ago)
2016-03-16 14:04:06.040443 process/ext_person_mention_by_map_person_mention/run.sh
2016-03-16 14:04:06.040464 ++ dirname process/ext_person_mention_by_map_person_mention/run.sh
2016-03-16 14:04:06.040483 + cd process/ext_person_mention_by_map_person_mention
2016-03-16 14:04:06.040503 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_person_mention_by_map_person_mention
2016-03-16 14:04:06.040522 + DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_person_mention_by_map_person_mention
2016-03-16 14:04:06.040542 + export DEEPDIVE_LOAD_FORMAT=tsv
2016-03-16 14:04:06.040561 + DEEPDIVE_LOAD_FORMAT=tsv
2016-03-16 14:04:06.040580 + deepdive compute execute 'input_sql= SELECT R0.doc_id AS "sentences.R0.doc_id", R0.sentence_index AS "sentences.R0.sentence_index", R0.sentence_text AS "sentences.R0.sentence_text"
2016-03-16 14:04:06.040601 FROM sentences R0
2016-03-16 14:04:06.040620         
2016-03-16 14:04:06.040639           ' 'command="$DEEPDIVE_APP"/udf/map_person_mention.py' output_relation=person_mention
2016-03-16 14:04:06.069911 Executing with the following configuration:
2016-03-16 14:04:06.069963  DEEPDIVE_NUM_PROCESSES=3
2016-03-16 14:04:06.069986  DEEPDIVE_NUM_PARALLEL_UNLOADS=1
2016-03-16 14:04:06.070007  DEEPDIVE_NUM_PARALLEL_LOADS=1
2016-03-16 14:04:06.070026  output_relation_tmp=dd_tmp_person_mention
2016-03-16 14:04:06.070044 
2016-03-16 14:04:06.220939 CREATE TABLE
2016-03-16 14:04:06.325295 CREATE TABLE
2016-03-16 14:04:06.443957 unloading to feed_processes-1: ' SELECT R0.doc_id AS "sentences.R0.doc_id", R0.sentence_index AS "sentences.R0.sentence_index", R0.sentence_text AS "sentences.R0.sentence_text"
2016-03-16 14:04:06.444053 FROM sentences R0
2016-03-16 14:04:06.444094         
2016-03-16 14:04:06.444119           '
2016-03-16 14:04:06.477787 Loading dd_tmp_person_mention from output_computed-1 (tsv format)
2016-03-16 14:04:08.551395 Traceback (most recent call last):
2016-03-16 14:04:08.551460   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 16, in <module>
2016-03-16 14:04:08.551485     sentence_text = "text",
2016-03-16 14:04:08.551506   File "/Users/SnehaS/local/lib/python/ddlib/util.py", line 232, in tsv_extractor
2016-03-16 14:04:08.551559     for out_row in generator(**row._asdict()):
2016-03-16 14:04:08.551584   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 30, in extract
2016-03-16 14:04:08.551604     for words in stopwords.words('english'):
2016-03-16 14:04:08.551623   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 99, in __getattr__
2016-03-16 14:04:08.551668     self.__load()
2016-03-16 14:04:08.551709   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 64, in __load
2016-03-16 14:04:08.551745     except LookupError: raise e
2016-03-16 14:04:08.551784 LookupError: 
2016-03-16 14:04:08.551809 **********************************************************************
2016-03-16 14:04:08.551831   Resource u'corpora/stopwords' not found.  Please use the NLTK
2016-03-16 14:04:08.551851   Downloader to obtain the resource:  >>> nltk.download()
2016-03-16 14:04:08.551871   Searched in:
2016-03-16 14:04:08.551890     - '/Users/SnehaS/nltk_data'
2016-03-16 14:04:08.551910     - '/usr/share/nltk_data'
2016-03-16 14:04:08.551930     - '/usr/local/share/nltk_data'
2016-03-16 14:04:08.551949     - '/usr/lib/nltk_data'
2016-03-16 14:04:08.551968     - '/usr/local/lib/nltk_data'
2016-03-16 14:04:08.551987 **********************************************************************
2016-03-16 14:04:08.553268 Traceback (most recent call last):
2016-03-16 14:04:08.553349   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 16, in <module>
2016-03-16 14:04:08.553372     sentence_text = "text",
2016-03-16 14:04:08.553394   File "/Users/SnehaS/local/lib/python/ddlib/util.py", line 232, in tsv_extractor
2016-03-16 14:04:08.553412     for out_row in generator(**row._asdict()):
2016-03-16 14:04:08.553431   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 30, in extract
2016-03-16 14:04:08.553452     for words in stopwords.words('english'):
2016-03-16 14:04:08.553472   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 99, in __getattr__
2016-03-16 14:04:08.553541     self.__load()
2016-03-16 14:04:08.553581   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 64, in __load
2016-03-16 14:04:08.553605     except LookupError: raise e
2016-03-16 14:04:08.553642 LookupError: 
2016-03-16 14:04:08.553674 **********************************************************************
2016-03-16 14:04:08.553699   Resource u'corpora/stopwords' not found.  Please use the NLTK
2016-03-16 14:04:08.553720   Downloader to obtain the resource:  >>> nltk.download()
2016-03-16 14:04:08.553740   Searched in:
2016-03-16 14:04:08.553760     - '/Users/SnehaS/nltk_data'
2016-03-16 14:04:08.553780     - '/usr/share/nltk_data'
2016-03-16 14:04:08.553802     - '/usr/local/share/nltk_data'
2016-03-16 14:04:08.553823     - '/usr/lib/nltk_data'
2016-03-16 14:04:08.553844     - '/usr/local/lib/nltk_data'
2016-03-16 14:04:08.553866 **********************************************************************
2016-03-16 14:04:08.588999 Traceback (most recent call last):
2016-03-16 14:04:08.589105   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 16, in <module>
2016-03-16 14:04:08.589132     sentence_text = "text",
2016-03-16 14:04:08.589156   File "/Users/SnehaS/local/lib/python/ddlib/util.py", line 232, in tsv_extractor
2016-03-16 14:04:08.589236     for out_row in generator(**row._asdict()):
2016-03-16 14:04:08.589330   File "/Users/SnehaS/Desktop/DR/planetaryIR-Repo/app/planetaryir/udf/map_person_mention.py", line 30, in extract
2016-03-16 14:04:08.589426     for words in stopwords.words('english'):
2016-03-16 14:04:08.589483   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 99, in __getattr__
2016-03-16 14:04:08.589679     self.__load()
2016-03-16 14:04:08.589752   File "//anaconda/lib/python2.7/site-packages/nltk/corpus/util.py", line 64, in __load
2016-03-16 14:04:08.589952     except LookupError: raise e
2016-03-16 14:04:08.589991 LookupError: 
2016-03-16 14:04:08.590016 **********************************************************************
2016-03-16 14:04:08.590038   Resource u'corpora/stopwords' not found.  Please use the NLTK
2016-03-16 14:04:08.590060   Downloader to obtain the resource:  >>> nltk.download()
2016-03-16 14:04:08.590081   Searched in:
2016-03-16 14:04:08.590113     - '/Users/SnehaS/nltk_data'
2016-03-16 14:04:08.590133     - '/usr/share/nltk_data'
2016-03-16 14:04:08.590153     - '/usr/local/share/nltk_data'
2016-03-16 14:04:08.590173     - '/usr/lib/nltk_data'
2016-03-16 14:04:08.590193     - '/usr/local/lib/nltk_data'
2016-03-16 14:04:08.590234 **********************************************************************
2016-03-16 14:04:08.611575 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 140: kill: (56154) - No such process
2016-03-16 14:04:08.611873 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 140: kill: (56167) - No such process
2016-03-16 14:04:08.611912 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 140: kill: (56168) - No such process
2016-03-16 14:04:08.614531 COPY 0
2016-03-16 14:04:08.620432 [ERROR] command='"$DEEPDIVE_APP"/udf/map_person_mention.py': PID 56154: finished with non-zero exit status (0)
2016-03-16 14:04:08.620730 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 138: 56160 Terminated: 15          mkmimo process-*.output \> output_computed-*
2016-03-16 14:04:08.620768 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 138: 56161 Terminated: 15          deepdive-load "$output_relation_tmp" output_computed-*
2016-03-16 14:04:08.624551 /Users/SnehaS/local/util/compute-driver/local/compute-execute: line 1: 56156 Terminated: 15          DEEPDIVE_CURRENT_PROCESS_INDEX=$i "$SHELL" -c "$command" < process-$i.input > process-$i.output
