2016-02-25 13:39:28.650725 # on Snehas-MacBook-Pro.local: deepdive do person_mention
2016-02-25 13:39:28.650952 # run/20160225/133923.379518000/plan.sh
2016-02-25 13:39:28.650970 # execution plan for data/person_mention
2016-02-25 13:39:28.650986 
2016-02-25 13:39:28.651005 : ## process/init/app ##########################################################
2016-02-25 13:39:28.651023 : # Done: 2016-02-24T17:00:00-0800 (20h 39m 23s ago)
2016-02-25 13:39:28.651040 : process/init/app/run.sh
2016-02-25 13:39:28.651057 : mark_done process/init/app
2016-02-25 13:39:28.651076 : ##############################################################################
2016-02-25 13:39:28.651092 
2016-02-25 13:39:28.651110 ## process/init/relation/articles ############################################
2016-02-25 13:39:28.651128 # Done: 2016-02-24T17:00:01-0800 (20h 39m 22s ago)
2016-02-25 13:39:28.651145 process/init/relation/articles/run.sh
2016-02-25 13:39:28.651161 ++ dirname process/init/relation/articles/run.sh
2016-02-25 13:39:28.651177 + cd process/init/relation/articles
2016-02-25 13:39:28.651193 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/init/relation/articles
2016-02-25 13:39:28.651209 + DEEPDIVE_CURRENT_PROCESS_NAME=process/init/relation/articles
2016-02-25 13:39:28.651226 + deepdive create table articles
2016-02-25 13:39:28.738144 CREATE TABLE
2016-02-25 13:39:28.739383 + deepdive load articles
2016-02-25 13:39:28.810391 Loading articles from input/articles.tsv.sh (tsv format)
2016-02-25 13:39:28.854004 COPY 1
2016-02-25 13:39:28.858402 mark_done process/init/relation/articles
2016-02-25 13:39:28.871270 ##############################################################################
2016-02-25 13:39:28.871333 
2016-02-25 13:39:28.871352 ## data/articles #############################################################
2016-02-25 13:39:28.871371 # Done: 2016-02-24T17:00:01-0800 (20h 39m 22s ago)
2016-02-25 13:39:28.871389 # no-op
2016-02-25 13:39:28.871409 mark_done data/articles
2016-02-25 13:39:28.882870 ##############################################################################
2016-02-25 13:39:28.882920 
2016-02-25 13:39:28.882941 ## process/ext_sentences_by_nlp_markup #######################################
2016-02-25 13:39:28.882960 # Done: 2016-02-25T11:32:02-0800 (2h 7m 21s ago)
2016-02-25 13:39:28.882995 process/ext_sentences_by_nlp_markup/run.sh
2016-02-25 13:39:28.887193 ++ dirname process/ext_sentences_by_nlp_markup/run.sh
2016-02-25 13:39:28.890129 + cd process/ext_sentences_by_nlp_markup
2016-02-25 13:39:28.890245 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_sentences_by_nlp_markup
2016-02-25 13:39:28.890288 + DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_sentences_by_nlp_markup
2016-02-25 13:39:28.890312 + export DEEPDIVE_LOAD_FORMAT=tsv
2016-02-25 13:39:28.890335 + DEEPDIVE_LOAD_FORMAT=tsv
2016-02-25 13:39:28.890354 + deepdive compute execute 'input_sql= SELECT R0.id AS "articles.R0.id", R0.content AS "articles.R0.content"
2016-02-25 13:39:28.890371 FROM articles R0
2016-02-25 13:39:28.890387         
2016-02-25 13:39:28.890404           ' 'command="$DEEPDIVE_APP"/udf/nlp_markup.sh' output_relation=sentences
2016-02-25 13:39:28.953047 Executing with the following configuration:
2016-02-25 13:39:28.953094  DEEPDIVE_NUM_PROCESSES=3
2016-02-25 13:39:28.953110  DEEPDIVE_NUM_PARALLEL_UNLOADS=1
2016-02-25 13:39:28.953136  DEEPDIVE_NUM_PARALLEL_LOADS=1
2016-02-25 13:39:28.953188  output_relation_tmp=dd_tmp_sentences
2016-02-25 13:39:28.953221 
2016-02-25 13:39:29.088434 CREATE TABLE
2016-02-25 13:39:29.187399 CREATE TABLE
2016-02-25 13:39:29.310170 unloading to feed_processes-1: ' SELECT R0.id AS "articles.R0.id", R0.content AS "articles.R0.content"
2016-02-25 13:39:29.310228 FROM articles R0
2016-02-25 13:39:29.310251         
2016-02-25 13:39:29.310273           '
2016-02-25 13:39:29.326709 Loading dd_tmp_sentences from output_computed-1 (tsv format)
2016-02-25 13:39:30.044377 Parsing with max_len=100
2016-02-25 13:39:30.054621 Parsing with max_len=100
2016-02-25 13:39:30.058158 Parsing with max_len=100
2016-02-25 13:39:30.270479 Adding annotator tokenize
2016-02-25 13:39:30.273633 Adding annotator tokenize
2016-02-25 13:39:30.276033 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-02-25 13:39:30.278231 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-02-25 13:39:30.281005 Adding annotator cleanxml
2016-02-25 13:39:30.282123 Adding annotator tokenize
2016-02-25 13:39:30.282504 Adding annotator cleanxml
2016-02-25 13:39:30.286405 TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
2016-02-25 13:39:30.291849 Adding annotator cleanxml
2016-02-25 13:39:30.311560 Adding annotator ssplit
2016-02-25 13:39:30.313170 Adding annotator ssplit
2016-02-25 13:39:30.314447 Adding annotator pos
2016-02-25 13:39:30.319600 Adding annotator pos
2016-02-25 13:39:30.323293 Adding annotator ssplit
2016-02-25 13:39:30.325495 Adding annotator pos
2016-02-25 13:39:32.244489 Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.8 sec].
2016-02-25 13:39:32.246771 Adding annotator lemma
2016-02-25 13:39:32.249148 Adding annotator ner
2016-02-25 13:39:32.369117 done [2.0 sec].
2016-02-25 13:39:32.369434 Adding annotator lemma
2016-02-25 13:39:32.370249 Adding annotator ner
2016-02-25 13:39:33.243128 Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [2.9 sec].
2016-02-25 13:39:33.243275 Adding annotator lemma
2016-02-25 13:39:33.244047 Adding annotator ner
2016-02-25 13:39:39.403094 Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [6.9 sec].
2016-02-25 13:39:39.494181 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [7.1 sec].
2016-02-25 13:39:40.758067 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [7.5 sec].
2016-02-25 13:39:43.455501 Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [4.0 sec].
2016-02-25 13:39:43.598620 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [4.2 sec].
2016-02-25 13:39:43.792001 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [3.0 sec].
2016-02-25 13:39:46.756314 Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [3.2 sec].
2016-02-25 13:39:46.758179 sutime.binder.1.
2016-02-25 13:39:46.758352 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-02-25 13:39:46.833167 done [3.4 sec].
2016-02-25 13:39:46.835647 sutime.binder.1.
2016-02-25 13:39:46.835714 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-02-25 13:39:47.254705 done [3.5 sec].
2016-02-25 13:39:47.259173 sutime.binder.1.
2016-02-25 13:39:47.259503 Initializing JollyDayHoliday for sutime with classpath:edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml
2016-02-25 13:39:47.492070 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-02-25 13:39:47.493529 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-02-25 13:39:47.559255 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-02-25 13:39:47.577003 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-02-25 13:39:48.178113 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/defs.sutime.txt
2016-02-25 13:39:48.245174 Feb 25, 2016 1:39:48 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:48.245244 INFO: Ignoring inactive rule: null
2016-02-25 13:39:48.246158 Feb 25, 2016 1:39:48 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:48.246226 INFO: Ignoring inactive rule: temporal-composite-8:ranges
2016-02-25 13:39:48.246455 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-02-25 13:39:48.270711 Adding annotator parse
2016-02-25 13:39:48.322941 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...Feb 25, 2016 1:39:48 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:48.323002 INFO: Ignoring inactive rule: null
2016-02-25 13:39:48.323892 Feb 25, 2016 1:39:48 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:48.323958 INFO: Ignoring inactive rule: temporal-composite-8:ranges
2016-02-25 13:39:48.324396 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-02-25 13:39:48.327004 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.sutime.txt
2016-02-25 13:39:48.337146 Adding annotator parse
2016-02-25 13:39:49.088472 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...Feb 25, 2016 1:39:49 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:49.088539 INFO: Ignoring inactive rule: null
2016-02-25 13:39:49.089636 Feb 25, 2016 1:39:49 PM edu.stanford.nlp.ling.tokensregex.CoreMapExpressionExtractor appendRules
2016-02-25 13:39:49.089691 INFO: Ignoring inactive rule: temporal-composite-8:ranges
2016-02-25 13:39:49.091240 Reading TokensRegex rules from edu/stanford/nlp/models/sutime/english.holidays.sutime.txt
2016-02-25 13:39:49.100697 Adding annotator parse
2016-02-25 13:40:16.615193 Loading parser from serialized file edu/stanford/nlp/models/srparser/englishSR.ser.gz ...done [28.3 sec].
2016-02-25 13:40:16.764041 Parsing document 1438...
2016-02-25 13:40:17.473454 done [29.2 sec].
2016-02-25 13:40:19.473200 done [30.4 sec].
2016-02-25 13:40:25.401839 COPY 65
2016-02-25 13:40:25.411802 Replacing sentences with dd_tmp_sentences
2016-02-25 13:40:25.490186 DROP TABLE
2016-02-25 13:40:25.556299 ALTER TABLE
2016-02-25 13:40:25.621917 ALTER TABLE
2016-02-25 13:40:25.687207 DROP TABLE
2016-02-25 13:40:25.744583 ANALYZE
2016-02-25 13:40:25.752823 mark_done process/ext_sentences_by_nlp_markup
2016-02-25 13:40:25.768976 ##############################################################################
2016-02-25 13:40:25.769026 
2016-02-25 13:40:25.769041 ## data/sentences ############################################################
2016-02-25 13:40:25.769060 # Done: 2016-02-25T11:32:02-0800 (2h 7m 21s ago)
2016-02-25 13:40:25.769079 # no-op
2016-02-25 13:40:25.769098 mark_done data/sentences
2016-02-25 13:40:25.781879 ##############################################################################
2016-02-25 13:40:25.781957 
2016-02-25 13:40:25.781981 ## process/ext_person_mention_by_map_person_mention ##########################
2016-02-25 13:40:25.782001 # Done: N/A
2016-02-25 13:40:25.782019 process/ext_person_mention_by_map_person_mention/run.sh
2016-02-25 13:40:25.787715 ++ dirname process/ext_person_mention_by_map_person_mention/run.sh
2016-02-25 13:40:25.790060 + cd process/ext_person_mention_by_map_person_mention
2016-02-25 13:40:25.790145 + export DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_person_mention_by_map_person_mention
2016-02-25 13:40:25.790180 + DEEPDIVE_CURRENT_PROCESS_NAME=process/ext_person_mention_by_map_person_mention
2016-02-25 13:40:25.790202 + export DEEPDIVE_LOAD_FORMAT=tsv
2016-02-25 13:40:25.790223 + DEEPDIVE_LOAD_FORMAT=tsv
2016-02-25 13:40:25.790256 + deepdive compute execute 'input_sql= SELECT R0.doc_id AS "sentences.R0.doc_id", R0.sentence_index AS "sentences.R0.sentence_index", R0.tokens AS "sentences.R0.tokens", R0.ner_tags AS "sentences.R0.ner_tags"
2016-02-25 13:40:25.790278 FROM sentences R0
2016-02-25 13:40:25.790298         
2016-02-25 13:40:25.790316           ' 'command="$DEEPDIVE_APP"/udf/map_person_mention.py' output_relation=person_mention
2016-02-25 13:40:25.854399 Executing with the following configuration:
2016-02-25 13:40:25.854448  DEEPDIVE_NUM_PROCESSES=3
2016-02-25 13:40:25.854466  DEEPDIVE_NUM_PARALLEL_UNLOADS=1
2016-02-25 13:40:25.854488  DEEPDIVE_NUM_PARALLEL_LOADS=1
2016-02-25 13:40:25.854529  output_relation_tmp=dd_tmp_person_mention
2016-02-25 13:40:25.854553 
2016-02-25 13:40:26.010200 NOTICE:  table "person_mention" does not exist, skipping
2016-02-25 13:40:26.013011 CREATE TABLE
2016-02-25 13:40:26.113131 CREATE TABLE
2016-02-25 13:40:26.232487 unloading to feed_processes-1: ' SELECT R0.doc_id AS "sentences.R0.doc_id", R0.sentence_index AS "sentences.R0.sentence_index", R0.tokens AS "sentences.R0.tokens", R0.ner_tags AS "sentences.R0.ner_tags"
2016-02-25 13:40:26.232552 FROM sentences R0
2016-02-25 13:40:26.232573         
2016-02-25 13:40:26.232592           '
2016-02-25 13:40:26.259482 Loading dd_tmp_person_mention from output_computed-1 (tsv format)
2016-02-25 13:40:29.255850 COPY 45
2016-02-25 13:40:29.260954 Replacing person_mention with dd_tmp_person_mention
2016-02-25 13:40:29.323879 DROP TABLE
2016-02-25 13:40:29.391118 ALTER TABLE
2016-02-25 13:40:29.456025 ALTER TABLE
2016-02-25 13:40:29.525195 DROP TABLE
2016-02-25 13:40:29.564104 ANALYZE
2016-02-25 13:40:29.570811 mark_done process/ext_person_mention_by_map_person_mention
2016-02-25 13:40:29.584259 ##############################################################################
2016-02-25 13:40:29.584316 
2016-02-25 13:40:29.584342 ## data/person_mention #######################################################
2016-02-25 13:40:29.584367 # Done: N/A
2016-02-25 13:40:29.584388 # no-op
2016-02-25 13:40:29.584410 mark_done data/person_mention
2016-02-25 13:40:29.597889 ##############################################################################
2016-02-25 13:40:29.597943 
